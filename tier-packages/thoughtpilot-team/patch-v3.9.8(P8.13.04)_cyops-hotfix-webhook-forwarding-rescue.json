{
  "showInUI": true,
  "blockId": "patch-v3.9.8(P8.13.04)_cyops-hotfix-webhook-forwarding-rescue",
  "description": "Restore broken Flask-to-Ghost patch forwarding (silent failure fix)",
  "target": "DEV",
  "version": "patch-v3.9.8(P8.13.04)_cyops-hotfix-webhook-forwarding-rescue",
  "enforceValidationGate": true,
  "strictRuntimeAudit": true,
  "runDryCheck": true,
  "forceRuntimeTrace": true,
  "requireMutationProof": true,
  "requireServiceUptime": true,

  "preCommit": {
    "backup": {
      "path": "/Users/sawyer/gitSync/_backups/gpt-cursor-runner/",
      "file": "20250729_patch-v3.9.8(P8.13.04)_cyops-hotfix-webhook-forwarding-rescue_backup_gpt-cursor-runner.tar.gz"
    },
    "shell": [
      "echo '[PATCH INIT] Hotpatching broken webhook forwarding system...'",
      "mkdir -p /Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs",
      "echo '[PRE-COMMIT] Created log directory for delivery confirmation'"
    ]
  },

  "mutations": [
    {
      "path": "/Users/sawyer/gitSync/gpt-cursor-runner/gpt_cursor_runner/webhook_handler.py",
      "contents": "#!/usr/bin/env python3\n\"\"\"\nWebhook Handler for GPT-Cursor Runner.\n\nHandles incoming webhook requests from GPT and other sources.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport requests\nfrom datetime import datetime\nfrom typing import Dict, Any\n\n# Import notification system\ntry:\n    from .slack_proxy import create_slack_proxy\n    slack_proxy = create_slack_proxy()\nexcept ImportError:\n    slack_proxy = None\n\n# Import event logger\ntry:\n    from .event_logger import event_logger\nexcept ImportError:\n    event_logger = None  # type: ignore\n\n\ndef get_patches_directory() -> str:\n    \"\"\"Get the patches directory from environment or use default.\"\"\"\n    # Check for environment variable first\n    patches_dir = os.getenv(\"PATCHES_DIRECTORY\")\n    if patches_dir:\n        return patches_dir\n    # Default to the centralized CYOPS location\n    default_dir = \"/Users/sawyer/gitSync/.cursor-cache/CYOPS/patches\"\n    # If default doesn't exist, try relative patches directory\n    if not os.path.exists(default_dir):\n        relative_dir = \"patches\"\n        if os.path.exists(relative_dir):\n            return relative_dir\n    return default_dir\n\n\ndef create_webhook_handler() -> Any:\n    \"\"\"Create webhook handler function for Flask integration.\"\"\"\n    return process_hybrid_block\n\n\ndef process_hybrid_block(block_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process a GPT hybrid block and save it as a patch.\"\"\"\n    try:\n        # Validate required fields\n        required_fields = [\"id\", \"role\", \"target_file\", \"patch\"]\n        for field in required_fields:\n            if field not in block_data:\n                error_msg = f\"Missing required field: {field}\"\n                if event_logger:\n                    event_logger.log_system_event(\n                        \"webhook_validation_error\",\n                        {\"error\": error_msg, \"block_data\": block_data},\n                    )\n                if slack_proxy:\n                    slack_proxy.notify_error(error_msg, context=\"process_hybrid_block\")\n                return {\"success\": False, \"error\": error_msg}\n\n        # Get patches directory from configuration\n        patches_dir = get_patches_directory()\n        os.makedirs(patches_dir, exist_ok=True)\n\n        # Generate timestamped filename\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"{block_data['id']}_{timestamp}.json\"\n        filepath = os.path.join(patches_dir, filename)\n\n        # Save the block\n        with open(filepath, \"w\") as f:\n            json.dump(block_data, f, indent=2)\n\n        # Log success\n        if event_logger:\n            event_logger.log_system_event(\n                \"patch_created\",\n                {\n                    \"patch_id\": block_data[\"id\"],\n                    \"target_file\": block_data.get(\"target_file\"),\n                    \"filepath\": filepath,\n                },\n            )\n\n        # Notify Slack of patch creation\n        if slack_proxy:\n            slack_proxy.notify_patch_created(block_data)\n\n        # Forward patch to Ghost Runner for execution with enhanced error handling\n        forward_success = forward_patch_to_ghost(block_data)\n\n        return {\n            \"success\": True,\n            \"message\": f\"Patch saved to {filename} and forwarded to Ghost Runner\",\n            \"filepath\": filepath,\n            \"patch_id\": block_data[\"id\"],\n            \"forwarded\": forward_success\n        }\n\n    except Exception as e:\n        error_msg = f\"Error processing hybrid block: {str(e)}\"\n        if event_logger:\n            event_logger.log_system_event(\n                \"webhook_error\", {\"error\": error_msg, \"block_data\": block_data}\n            )\n        # Notify Slack of error\n        if slack_proxy:\n            slack_proxy.notify_error(error_msg, context=\"process_hybrid_block\")\n        return {\"success\": False, \"error\": error_msg}\n\n\ndef forward_patch_to_ghost(block_data: Dict[str, Any]) -> bool:\n    \"\"\"Forward patch to Ghost Runner with comprehensive error handling.\"\"\"\n    try:\n        # Try multiple Ghost Runner endpoints\n        ghost_endpoints = [\n            \"http://localhost:5053/patch\",\n            \"http://127.0.0.1:5053/patch\",\n            \"http://localhost:5053/execute\"\n        ]\n\n        for endpoint in ghost_endpoints:\n            try:\n                print(f\"[FORWARD] Attempting to forward to {endpoint}\")\n                response = requests.post(endpoint, json=block_data, timeout=15)\n                \n                if response.status_code == 200:\n                    print(f\"[FORWARD SUCCESS] Patch {block_data['id']} sent to Ghost Runner at {endpoint}\")\n                    if event_logger:\n                        event_logger.log_system_event(\n                            \"patch_forwarded_to_ghost\",\n                            {\n                                \"patch_id\": block_data[\"id\"],\n                                \"endpoint\": endpoint,\n                                \"ghost_response\": response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text,\n                            },\n                        )\n                    return True\n                else:\n                    print(f\"[FORWARD ERROR] Ghost responded with status: {response.status_code} from {endpoint}\")\n                    \n            except requests.exceptions.RequestException as e:\n                print(f\"[FORWARD EXCEPTION] Failed to connect to {endpoint}: {str(e)}\")\n                continue\n\n        # If all endpoints failed, log the failure\n        error_msg = f\"All Ghost Runner endpoints failed for patch {block_data['id']}\"\n        print(f\"[FORWARD FAILURE] {error_msg}\")\n        if event_logger:\n            event_logger.log_system_event(\n                \"ghost_forward_failed\",\n                {\n                    \"patch_id\": block_data[\"id\"],\n                    \"error\": error_msg,\n                },\n            )\n        return False\n\n    except Exception as e:\n        error_msg = f\"Unexpected error forwarding patch: {str(e)}\"\n        print(f\"[FORWARD EXCEPTION] {error_msg}\")\n        if event_logger:\n            event_logger.log_system_event(\n                \"ghost_forward_error\",\n                {\n                    \"patch_id\": block_data[\"id\"],\n                    \"error\": error_msg,\n                },\n            )\n        return False\n\n\ndef process_summary(summary_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Process a summary and save it to the summaries directory.\"\"\"\n    try:\n        # Validate required fields\n        if \"content\" not in summary_data:\n            error_msg = \"Missing required field: content\"\n            if event_logger:\n                event_logger.log_system_event(\n                    \"summary_validation_error\",\n                    {\"error\": error_msg, \"summary_data\": summary_data},\n                )\n            return {\"success\": False, \"error\": error_msg}\n\n        # Get summaries directory from environment or use default\n        summaries_dir = os.getenv(\n            \"SUMMARIES_DIRECTORY\",\n            \"/Users/sawyer/gitSync/.cursor-cache/CYOPS/summaries\",\n        )\n        os.makedirs(summaries_dir, exist_ok=True)\n\n        # Generate filename\n        summary_id = summary_data.get(\"id\", f\"summary-{int(datetime.now().timestamp())}\")\n        filename = f\"{summary_id}.md\"\n        filepath = os.path.join(summaries_dir, filename)\n\n        # Save the summary\n        with open(filepath, \"w\") as f:\n            f.write(summary_data[\"content\"])\n\n        # Log success\n        if event_logger:\n            event_logger.log_system_event(\n                \"summary_created\",\n                {\n                    \"summary_id\": summary_id,\n                    \"filepath\": filepath,\n                },\n            )\n\n        return {\n            \"success\": True,\n            \"message\": f\"Summary saved to {filename}\",\n            \"filepath\": filepath,\n            \"summary_id\": summary_id,\n        }\n\n    except Exception as e:\n        error_msg = f\"Error processing summary: {str(e)}\"\n        if event_logger:\n            event_logger.log_system_event(\n                \"summary_error\", {\"error\": error_msg, \"summary_data\": summary_data}\n            )\n        return {\"success\": False, \"error\": error_msg}"
    },
    {
      "path": "/Users/sawyer/gitSync/gpt-cursor-runner/scripts/ghost-runner.js",
      "contents": "#!/usr/bin/env node\n\n/**\n * Ghost Runner Service\n * Handles patch execution and monitoring for both MAIN and CYOPS environments\n * \n * Usage:\n *   node scripts/ghost-runner.js\n *   node scripts/ghost-runner.js --env=MAIN\n *   node scripts/ghost-runner.js --env=CYOPS\n */\n\nconst fs = require('fs');\nconst path = require('path');\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst { exec } = require('child_process');\n\n// Configuration\nconst PORT = process.env.GHOST_RUNNER_PORT || 5053;\nconst ENV = process.argv.find(arg => arg.startsWith('--env='))?.split('=')[1] || 'CYOPS';\nconst CACHE_ROOT = '/Users/sawyer/gitSync/.cursor-cache';\nconst PATCHES_DIR = path.join(CACHE_ROOT, ENV, 'patches');\nconst SUMMARIES_DIR = path.join(CACHE_ROOT, ENV, 'summaries');\nconst HEARTBEAT_DIR = path.join(CACHE_ROOT, ENV, '.heartbeat');\nconst LOGS_DIR = path.join(PATCHES_DIR, '.logs');\n\n// Ensure directories exist\n[PATCHES_DIR, SUMMARIES_DIR, HEARTBEAT_DIR, LOGS_DIR].forEach(dir => {\n  if (!fs.existsSync(dir)) {\n    fs.mkdirSync(dir, { recursive: true });\n  }\n});\n\nconst app = express();\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true }));\n\n// Logging\nconst log = (message) => {\n  const timestamp = new Date().toISOString();\n  console.log(`[${timestamp}] [GHOST-RUNNER:${ENV}] ${message}`);\n};\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.json({\n    status: 'healthy',\n    service: 'ghost-runner',\n    environment: ENV,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    port: PORT,\n    endpoints: ['/health', '/status', '/patches', '/execute', '/monitor']\n  });\n});\n\n// Status endpoint\napp.get('/status', (req, res) => {\n  const status = {\n    service: 'ghost-runner',\n    environment: ENV,\n    status: 'running',\n    port: PORT,\n    timestamp: new Date().toISOString(),\n    patches: {\n      pending: 0,\n      completed: 0,\n      failed: 0\n    },\n    directories: {\n      patches: PATCHES_DIR,\n      summaries: SUMMARIES_DIR,\n      heartbeat: HEARTBEAT_DIR\n    }\n  };\n\n  // Count patches\n  try {\n    if (fs.existsSync(PATCHES_DIR)) {\n      const files = fs.readdirSync(PATCHES_DIR);\n      status.patches.pending = files.filter(f => f.endsWith('.json')).length;\n    }\n    \n    const completedDir = path.join(PATCHES_DIR, '.completed');\n    const failedDir = path.join(PATCHES_DIR, '.failed');\n    \n    if (fs.existsSync(completedDir)) {\n      status.patches.completed = fs.readdirSync(completedDir).filter(f => f.endsWith('.json')).length;\n    }\n    \n    if (fs.existsSync(failedDir)) {\n      status.patches.failed = fs.readdirSync(failedDir).filter(f => f.endsWith('.json')).length;\n    }\n  } catch (error) {\n    log(`Error counting patches: ${error.message}`);\n  }\n\n  res.json(status);\n});\n\n// List patches endpoint\napp.get('/patches', (req, res) => {\n  try {\n    const files = fs.readdirSync(PATCHES_DIR);\n    const patches = files\n      .filter(f => f.endsWith('.json'))\n      .map(f => ({\n        name: f,\n        path: path.join(PATCHES_DIR, f),\n        size: fs.statSync(path.join(PATCHES_DIR, f)).size,\n        modified: fs.statSync(path.join(PATCHES_DIR, f)).mtime\n      }));\n    \n    res.json({\n      environment: ENV,\n      patches: patches,\n      count: patches.length\n    });\n  } catch (error) {\n    res.status(500).json({\n      error: 'Failed to list patches',\n      message: error.message\n    });\n  }\n});\n\n// Receive and execute patch endpoint\napp.post('/patch', (req, res) => {\n  const patch = req.body;\n  \n  if (!patch || !patch.id) {\n    return res.status(400).json({\n      error: 'Invalid patch data: missing id'\n    });\n  }\n\n  log(`Received patch: ${patch.id}`);\n\n  // Save patch to file\n  const patchPath = path.join(PATCHES_DIR, `${patch.id}.json`);\n  try {\n    fs.writeFileSync(patchPath, JSON.stringify(patch, null, 2));\n    log(`Patch saved to: ${patchPath}`);\n  } catch (error) {\n    log(`Failed to save patch: ${error.message}`);\n    return res.status(500).json({\n      error: 'Failed to save patch',\n      message: error.message\n    });\n  }\n\n  // Execute the patch immediately\n  executePatch(patch.id, patchPath, res);\n});\n\n// Execute patch endpoint (for existing patches)\napp.post('/execute', (req, res) => {\n  const { patchId } = req.body;\n  \n  if (!patchId) {\n    return res.status(400).json({\n      error: 'patchId is required'\n    });\n  }\n\n  const patchPath = path.join(PATCHES_DIR, `${patchId}.json`);\n  \n  if (!fs.existsSync(patchPath)) {\n    return res.status(404).json({\n      error: 'Patch not found',\n      patchId: patchId\n    });\n  }\n\n  log(`Executing patch: ${patchId}`);\n  executePatch(patchId, patchPath, res);\n});\n\n// Patch execution function with enhanced logging\nfunction executePatch(patchId, patchPath, res) {\n  log(`Starting execution of patch: ${patchId}`);\n  \n  // Log the patch execution attempt\n  const logEntry = `[${new Date().toISOString()}] Executing patch: ${patchId}\\n`;\n  const logFile = path.join(LOGS_DIR, 'patch-execution.log');\n  try {\n    fs.appendFileSync(logFile, logEntry);\n  } catch (error) {\n    log(`Failed to write to log file: ${error.message}`);\n  }\n\n  // Execute patch using the patch executor\n  const executorScript = path.join(__dirname, 'patch-executor.js');\n  const command = `node \"${executorScript}\" \"${patchPath}\"`;\n\n  exec(command, { cwd: __dirname }, (error, stdout, stderr) => {\n    if (error) {\n      log(`Patch execution failed: ${error.message}`);\n      res.status(500).json({\n        error: 'Patch execution failed',\n        message: error.message,\n        stderr: stderr\n      });\n    } else {\n      log(`Patch executed successfully: ${patchId}`);\n      res.json({\n        success: true,\n        patchId: patchId,\n        output: stdout\n      });\n    }\n  });\n}\n\n// Monitor endpoint\napp.get('/monitor', (req, res) => {\n  const monitor = {\n    service: 'ghost-runner',\n    environment: ENV,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    memory: process.memoryUsage(),\n    directories: {\n      patches: {\n        path: PATCHES_DIR,\n        exists: fs.existsSync(PATCHES_DIR),\n        readable: fs.accessSync ? (() => {\n          try { fs.accessSync(PATCHES_DIR, fs.constants.R_OK); return true; } \n          catch { return false; }\n        })() : true\n      },\n      summaries: {\n        path: SUMMARIES_DIR,\n        exists: fs.existsSync(SUMMARIES_DIR),\n        readable: fs.accessSync ? (() => {\n          try { fs.accessSync(SUMMARIES_DIR, fs.constants.R_OK); return true; } \n          catch { return false; }\n        })() : true\n      },\n      heartbeat: {\n        path: HEARTBEAT_DIR,\n        exists: fs.existsSync(HEARTBEAT_DIR),\n        readable: fs.accessSync ? (() => {\n          try { fs.accessSync(HEARTBEAT_DIR, fs.constants.R_OK); return true; } \n          catch { return false; }\n        })() : true\n      }\n    }\n  };\n\n  res.json(monitor);\n});\n\n// Heartbeat endpoint\napp.get('/heartbeat', (req, res) => {\n  const heartbeat = {\n    service: 'ghost-runner',\n    environment: ENV,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    status: 'alive'\n  };\n\n  // Write heartbeat to file\n  const heartbeatFile = path.join(HEARTBEAT_DIR, 'ghost-runner-heartbeat.json');\n  try {\n    fs.writeFileSync(heartbeatFile, JSON.stringify(heartbeat, null, 2));\n  } catch (error) {\n    log(`Failed to write heartbeat: ${error.message}`);\n  }\n\n  res.json(heartbeat);\n});\n\n// Start server\napp.listen(PORT, () => {\n  log(`Ghost Runner started on port ${PORT} for environment ${ENV}`);\n  log(`Patches directory: ${PATCHES_DIR}`);\n  log(`Summaries directory: ${SUMMARIES_DIR}`);\n  log(`Heartbeat directory: ${HEARTBEAT_DIR}`);\n  log(`Logs directory: ${LOGS_DIR}`);\n});\n\n// Graceful shutdown\nprocess.on('SIGINT', () => {\n  log('Shutting down Ghost Runner...');\n  process.exit(0);\n});\n\nprocess.on('SIGTERM', () => {\n  log('Shutting down Ghost Runner...');\n  process.exit(0);\n});\n\n// Error handling\nprocess.on('uncaughtException', (error) => {\n  log(`Uncaught Exception: ${error.message}`);\n  log(`Stack: ${error.stack}`);\n  process.exit(1);\n});\n\nprocess.on('unhandledRejection', (reason, promise) => {\n  log(`Unhandled Rejection at: ${promise}, reason: ${reason}`);\n  process.exit(1);\n});"
    }
  ],

  "postMutationBuild": {
    "shell": [
      "echo '[POST-MUTATION] Starting service restart sequence...'",
      "( kill $(cat /Users/sawyer/gitSync/gpt-cursor-runner/pids/python-runner.pid) 2>/dev/null || echo 'No Python process to kill' )",
      "sleep 2",
      "( export PYTHON_PORT=5555 && nohup python3 -m gpt_cursor_runner.main > /Users/sawyer/gitSync/gpt-cursor-runner/logs/python-runner.log 2>&1 & echo $! > /Users/sawyer/gitSync/gpt-cursor-runner/pids/python-runner.pid )",
      "echo '[POST-MUTATION] Python Flask app restarted'",
      "( kill $(cat /Users/sawyer/gitSync/gpt-cursor-runner/pids/ghost-runner-CYOPS.pid) 2>/dev/null || echo 'No Ghost Runner process to kill' )",
      "sleep 2",
      "( cd /Users/sawyer/gitSync/gpt-cursor-runner && nohup node scripts/ghost-runner.js --env=CYOPS > logs/ghost-runner-CYOPS.log 2>&1 & echo $! > pids/ghost-runner-CYOPS.pid )",
      "echo '[POST-MUTATION] Ghost Runner restarted'",
      "sleep 5",
      "echo '[POST-MUTATION] Services restarted, waiting for startup...'"
    ]
  },

  "validate": {
    "shell": [
      "echo '[VALIDATION] Starting comprehensive webhook forwarding test...'",
      "sleep 3",
      "( timeout 30 curl -s http://localhost:5555/health | grep -q 'healthy' && echo '✅ Flask app healthy' || echo '❌ Flask app not responding' )",
      "( timeout 30 curl -s http://localhost:5053/health | grep -q 'healthy' && echo '✅ Ghost Runner healthy' || echo '❌ Ghost Runner not responding' )",
      "echo '[VALIDATION] Testing end-to-end webhook forwarding...'",
      "( timeout 30 curl -s -X POST -H 'Content-Type: application/json' -d '{\"id\":\"verify-hotpatch-v1\",\"role\":\"command_patch\",\"target_file\":\"/Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/delivery-confirmation.log\",\"patch\":\"echo \\\"[✅ HOTPATCH EXECUTION TEST] at $(date)\\\" >> /Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/delivery-confirmation.log\"}' http://localhost:5555/webhook )",
      "sleep 5",
      "( cat /Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/delivery-confirmation.log | grep -q 'HOTPATCH EXECUTION TEST' && echo '✅ End-to-end webhook forwarding confirmed' || echo '❌ Webhook forwarding failed' )",
      "echo '[VALIDATION] Testing external webhook endpoint...'",
      "( timeout 30 curl -s -X POST -H 'Content-Type: application/json' -d '{\"id\":\"external-test-v1\",\"role\":\"command_patch\",\"target_file\":\"/Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/external-test.log\",\"patch\":\"echo \\\"[✅ EXTERNAL WEBHOOK TEST] at $(date)\\\" >> /Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/external-test.log\"}' https://webhook-thoughtmarks.THOUGHTMARKS.app/webhook )",
      "sleep 5",
      "( cat /Users/sawyer/gitSync/.cursor-cache/CYOPS/patches/.logs/external-test.log | grep -q 'EXTERNAL WEBHOOK TEST' && echo '✅ External webhook endpoint confirmed' || echo '❌ External webhook endpoint failed' )"
    ]
  },

  "final": {
    "git": {
      "commit": "[HOTPATCH P8.13.04] cyops-hotfix-webhook-forwarding-rescue — Restore end-to-end patch delivery",
      "tag": "patch-v3.9.8(P8.13.04)_cyops-hotfix-webhook-forwarding-rescue"
    },
    "summary": "✅ patch-v3.9.8(P8.13.04)_cyops-hotfix-webhook-forwarding-rescue: Patch forwarding restored and confirmed operational.",
    "summaryFile": "/Users/sawyer/gitSync/.cursor-cache/CYOPS/summaries/summary-cyops-hotfix-webhook-forwarding-rescue.md"
  },

  "blockCommitOnError": true,
  "watchConsole": true,
  "execution": {
    "autoReleaseTimeoutMs": 30000,
    "onReloadHang": "Move to background and resume automatically"
  }
} 